{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danhearn\\.conda\\envs\\diffusertrack\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\danhearn\\.conda\\envs\\diffusertrack\\Lib\\site-packages\\kornia\\feature\\lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n",
      "unet\\diffusion_pytorch_model.safetensors not found\n",
      "Loading pipeline components...:   0%|          | 0/3 [00:00<?, ?it/s]An error occurred while trying to fetch C:\\Users\\danhearn\\.cache\\huggingface\\hub\\models--teticio--audio-diffusion-ddim-256\\snapshots\\f5606c5138496ecdcbd096a4446eb6d03ae690cb\\unet: Error no file named diffusion_pytorch_model.safetensors found in directory C:\\Users\\danhearn\\.cache\\huggingface\\hub\\models--teticio--audio-diffusion-ddim-256\\snapshots\\f5606c5138496ecdcbd096a4446eb6d03ae690cb\\unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "Loading pipeline components...: 100%|██████████| 3/3 [00:00<00:00, 13.04it/s]\n",
      "An error occurred while trying to fetch teticio/audio-diffusion-ddim-256: teticio/audio-diffusion-ddim-256 does not appear to have a file named diffusion_pytorch_model.safetensors.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import asyncio\n",
    "import threading\n",
    "from librosa.beat import beat_track\n",
    "from pythonosc import dispatcher, osc_server\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from diffusers import DiffusionPipeline, DDIMScheduler, AudioDiffusionPipeline\n",
    "from diffusers_local import UNet2DModel as UNet2DModel_local\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "from NetworkBending import NetworkBending\n",
    "import time  # for safely terminating the loop\n",
    "\n",
    "# Create a global lock for synchronizing OSC parameter updates\n",
    "osc_lock = threading.Lock()\n",
    "\n",
    "# Instantiate NetworkBending object\n",
    "NB = NetworkBending()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "audio_diffusion = DiffusionPipeline.from_pretrained(\"teticio/audio-diffusion-ddim-256\")\n",
    "# apply the custom unet model so we can Networkbend the audio\n",
    "audio_diffusion.unet = UNet2DModel_local.from_pretrained(\"teticio/audio-diffusion-ddim-256\", subfolder=\"unet\", network_bending=NB)\n",
    "\n",
    "#set the scheduler to DDIM\n",
    "audio_diffusion.scheduler = DDIMScheduler.from_pretrained(\"teticio/audio-diffusion-ddim-256\", subfolder=\"scheduler\")\n",
    "\n",
    "audio_diffusion.to(device)\n",
    "\n",
    "ds = load_dataset('teticio/audio-diffusion-256')\n",
    "generator=torch.Generator(device=\"cpu\").manual_seed(42)\n",
    "\n",
    "alpha = 0\n",
    "latent1 = 0\n",
    "latent2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_it(audio: np.ndarray,\n",
    "        sample_rate: int,\n",
    "        loops: int = 4) -> np.ndarray:\n",
    "    \"\"\"Loop audio\n",
    "\n",
    "    Args:\n",
    "        audio (np.ndarray): audio as numpy array\n",
    "        sample_rate (int): sample rate of audio\n",
    "        loops (int): number of times to loop\n",
    "\n",
    "    Returns:\n",
    "        (float, np.ndarray): sample rate and raw audio or None\n",
    "    \"\"\"\n",
    "    _, beats = beat_track(y=audio, sr=sample_rate, units='samples')\n",
    "    for beats_in_bar in [16, 12, 8, 4]:\n",
    "        if len(beats) > beats_in_bar:\n",
    "            return np.tile(audio[beats[0]:beats[beats_in_bar]], loops)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load 20 images from the dataset\n",
    "images = []\n",
    "\n",
    "for i in range(10):\n",
    "    images.append(random.choice(ds['train'])['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]c:\\Users\\danhearn\\Documents\\GitHub\\diffusertrack\\diffusers_local\\models\\attention_processor.py:2367: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "100%|██████████| 100/100 [00:02<00:00, 35.19it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 41.35it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 42.13it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 41.24it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 40.83it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 41.28it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 41.29it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 42.42it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 42.87it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 42.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#encode images in latent space\n",
    "encoded_images = []\n",
    "\n",
    "for i in range(10):\n",
    "    noise = audio_diffusion.encode([images[i]], steps=100)\n",
    "    encoded_images.append(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for encoded_image in encoded_images:\n",
    "    plt.imshow(encoded_image.cpu().squeeze(), cmap='gray')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(address, *args):\n",
    "    global alpha, latent1, latent2\n",
    "    if address == \"/alpha\":\n",
    "        alpha = args[0]\n",
    "    if address == \"/latent1\" and latent2 != args[0]:\n",
    "        latent1 = int(args[0])\n",
    "    if address == \"/latent2\" and latent1 != args[0]:\n",
    "        latent2 = int(args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OSC server started - listening on port 9999\n"
     ]
    }
   ],
   "source": [
    "#osc listener\n",
    "from pythonosc import dispatcher, osc_server\n",
    "\n",
    "ip=\"127.0.0.1\"\n",
    "port=9999\n",
    "\n",
    "d = dispatcher.Dispatcher()\n",
    "# Map incoming OSC messages to the osc_receive method\n",
    "d.map(\"/rotate_x_radian\",  NB.osc_receive)\n",
    "d.map(\"/rotate_y_radian\", NB.osc_receive)\n",
    "d.map(\"/rotate_z_radian\", NB.osc_receive)\n",
    "d.map(\"/rotate_x_scaling_factor\", NB.osc_receive)\n",
    "d.map(\"/rotate_y_scaling_factor\", NB.osc_receive)\n",
    "d.map(\"/rotate_z_scaling_factor\", NB.osc_receive)\n",
    "d.map(\"/scale_factor\", NB.osc_receive)\n",
    "d.map(\"/layer\", NB.osc_receive)\n",
    "d.map(\"/scale\", NB.osc_receive)\n",
    "d.map(\"/reflect\", NB.osc_receive)\n",
    "d.map(\"/erosion\", NB.osc_receive)\n",
    "d.map(\"/dilation\", NB.osc_receive)\n",
    "d.map(\"/gradient\", NB.osc_receive)\n",
    "d.map(\"/sobel\", NB.osc_receive)\n",
    "d.map(\"/add_rand_rows\", NB.osc_receive)\n",
    "d.map(\"/normalize\", NB.osc_receive)\n",
    "d.map(\"/rotate_x\", NB.osc_receive)\n",
    "d.map(\"/rotate_y\", NB.osc_receive)\n",
    "d.map(\"/rotate_z\", NB.osc_receive)\n",
    "d.map(\"/alpha\", interpolation)\n",
    "d.map(\"/latent1\", interpolation)\n",
    "d.map(\"/latent2\", interpolation)\n",
    "\n",
    "s = osc_server.ThreadingOSCUDPServer((ip, port), d)\n",
    "\n",
    "osc_thread = threading.Thread(target=s.serve_forever)\n",
    "osc_thread.daemon = True # This will allow the main program to exit even if the OSC server is still running\n",
    "osc_thread.start()\n",
    "print(\"OSC server started - listening on port 9999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 28.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 46.16it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 44.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.15it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.57it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.09it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.55it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.02it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 38.75it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.38it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.60it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.86it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.40it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.74it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.12it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.17it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.13it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.80it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.33it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.21it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.54it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 45.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.51it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.38it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.97it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.92it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.44it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 38.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.21it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.21it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.02it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.58it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 43.34it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 42.78it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.95it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.28it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.01it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.08it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.25it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.75it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.49it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 39.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 41.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.94it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 38.05it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 40.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating the loop gracefully.\n"
     ]
    }
   ],
   "source": [
    "# Main loop for image generation\n",
    "try:\n",
    "    while True:\n",
    "        with osc_lock:  # Ensure that network bending is thread-safe\n",
    "            output = audio_diffusion(steps=10,\n",
    "            noise=AudioDiffusionPipeline.slerp(encoded_images[latent1], encoded_images[latent2], alpha),\n",
    "            generator=generator, eta=0)\n",
    "            output.images[0].save(\"generated_image.png\")\n",
    "            sf.write(\"output_audio.wav\", output.audios[0, 0], audio_diffusion.mel.get_sample_rate())\n",
    "\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    s.shutdown()\n",
    "    print(\"Terminating the loop gracefully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusertrack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
